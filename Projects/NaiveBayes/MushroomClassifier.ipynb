{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revise conditional probabilty from here - \n",
    "#https://www.youtube.com/watch?v=9wCnvr7Xw4E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(A|B) = (P(B|A) * P(A))/P(B)\n",
    "\n",
    "# - P(B|A) - Likelihood\n",
    "# - P(A) - Prior prob of A \n",
    "# - P(B) - prob of given B knowledge - Normalisation - Marginal probability\n",
    "# - P(A|B) - posterior probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption Naive Bayes Classifier makes on top of Bayes Theorem\n",
    "# All features are independent to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Naive Bayes\n",
    "- Mushroom Dataset\n",
    "- Goal is to predict the class of mushrooms, given some features of the mushrooms. We will use Naive Bayes Model for this classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./mushrooms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  type cap_shape cap_surface cap_color bruises odor gill_attachment  \\\n",
      "0    p         x           s         n       t    p               f   \n",
      "1    e         x           s         y       t    a               f   \n",
      "2    e         b           s         w       t    l               f   \n",
      "3    p         x           y         w       t    p               f   \n",
      "4    e         x           s         g       f    n               f   \n",
      "\n",
      "  gill_spacing gill_size gill_color  ... stalk_surface_below_ring  \\\n",
      "0            c         n          k  ...                        s   \n",
      "1            c         b          k  ...                        s   \n",
      "2            c         b          n  ...                        s   \n",
      "3            c         n          n  ...                        s   \n",
      "4            w         b          k  ...                        s   \n",
      "\n",
      "  stalk_color_above_ring stalk_color_below_ring veil_type veil_color  \\\n",
      "0                      w                      w         p          w   \n",
      "1                      w                      w         p          w   \n",
      "2                      w                      w         p          w   \n",
      "3                      w                      w         p          w   \n",
      "4                      w                      w         p          w   \n",
      "\n",
      "  ring_number ring_type spore_print_color population habitat  \n",
      "0           o         p                 k          s       u  \n",
      "1           o         p                 n          n       g  \n",
      "2           o         p                 n          n       m  \n",
      "3           o         p                 k          s       u  \n",
      "4           o         e                 n          a       g  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "(8124, 23)\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e' 'p']\n",
      "['b' 'c' 'f' 'k' 's' 'x']\n",
      "['f' 'g' 's' 'y']\n",
      "['b' 'c' 'e' 'g' 'n' 'p' 'r' 'u' 'w' 'y']\n",
      "['f' 't']\n",
      "['a' 'c' 'n' 's' 'v' 'y']\n",
      "['d' 'g' 'l' 'm' 'p' 'u' 'w']\n"
     ]
    }
   ],
   "source": [
    "data = df.values\n",
    "print(np.unique(data[:,0]))\n",
    "print(np.unique(data[:,1]))\n",
    "print(np.unique(data[:,2]))\n",
    "print(np.unique(data[:,3]))\n",
    "print(np.unique(data[:,4]))\n",
    "print(np.unique(data[:,21]))\n",
    "print(np.unique(data[:,22]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Encode the categorial data into numerical data\n",
    "\n",
    "- We can do this by:\n",
    "- FOR each column in dataset, 1. create a dictionary 2. then FOR each entry in the given column, 2.1 assign unique numerical values to the given alphabet.\n",
    "- OR,\n",
    "- USE skikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[0 1 2 3 4 5 6]\n",
      "['u' 'g' 'm' ... 'l' 'l' 'l']\n",
      "['d' 'g' 'l' 'm' 'p' 'u' 'w']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "ls = LabelEncoder() # ls.fit_transform() returns encoded labels\n",
    "# Below - apply transformation to each column - apply a operation on pandas dataframe that operation is specified in a function - which in this case is ls.fit_transform()\n",
    "df_encoded = df.apply(ls.fit_transform)\n",
    "print(type(df_encoded))\n",
    "feature22 = df_encoded.iloc[:,22]\n",
    "print(np.unique(feature22))\n",
    "feature22_inverse = ls.inverse_transform(df_encoded.iloc[:,22]) # Note: LabelEncoder.fit applied to a dataframe, LabelEncoder class holds the last fitted column labels only.\n",
    "print(feature22_inverse)\n",
    "print(np.unique(feature22_inverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 1 2 3 4 5]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5]\n",
      "[0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_encoded = df_encoded.values\n",
    "print(np.unique(data_encoded[:,0]))\n",
    "print(np.unique(data_encoded[:,1]))\n",
    "print(np.unique(data_encoded[:,2]))\n",
    "print(np.unique(data_encoded[:,3]))\n",
    "print(np.unique(data_encoded[:,21]))\n",
    "print(np.unique(data_encoded[:,22]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 5 2 4 1 6 1 0 1 4 0 3 2 2 7 7 0 2 1 4 2 3 5]\n",
      " [0 5 2 9 1 0 1 0 0 4 0 2 2 2 7 7 0 2 1 4 3 2 1]\n",
      " [0 0 2 8 1 3 1 0 0 5 0 2 2 2 7 7 0 2 1 4 3 2 3]\n",
      " [1 5 3 8 1 6 1 0 1 5 0 3 2 2 7 7 0 2 1 4 2 3 5]\n",
      " [0 5 2 3 0 5 1 1 0 4 1 3 2 2 7 7 0 2 1 0 3 0 1]]\n",
      "(8124, 23)\n"
     ]
    }
   ],
   "source": [
    "print(data_encoded[:5,:])\n",
    "print(data_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Break the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6499, 22)\n",
      "(6499,)\n",
      "(1625, 22)\n",
      "(1625,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = data_encoded[:,1:]\n",
    "y = data_encoded[:,0]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2)\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of types of mushrooms\n",
    "np.unique(ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Building our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True False False False False False]\n",
      "2\n",
      "[False False False  True  True  True False  True]\n",
      "4\n",
      "[False  True  True  True  True  True False  True]\n",
      "6\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0, 5, 5, 1, 1, 1, 0, 1])\n",
    "\n",
    "print(a == 5)\n",
    "print(np.sum(a == 5))\n",
    "print(a == 1)\n",
    "print(np.sum(a == 1))\n",
    "print(a >= 1)\n",
    "print(np.sum(a >= 1))\n",
    "\n",
    "b = np.array([0, 1, 0, 0, 1, 1, 0, 1])\n",
    "print(b[a == 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_prob(ytrain, label):\n",
    "    total_examples = ytrain.shape[0]\n",
    "    class_example = np.sum(ytrain == label)\n",
    "    return (class_example)/float(total_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_prob(xtrain, ytrain, feature_col_index, feature_col_val,label): # label means class c\n",
    "    xtrain_filtered_by_label = xtrain[ytrain == label]\n",
    "    numerator = np.sum(xtrain_filtered_by_label[:,feature_col_index] == feature_col_val)\n",
    "    denominator = np.sum(ytrain == label)\n",
    "    return numerator/float(denominator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Compute Posterior probability for each test example and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(xtrain, ytrain, xtest):\n",
    "    \"\"\"here xtest is a single testing point with n features \"\"\"\n",
    "\n",
    "    posterior_prob_list = [] # this will hold list of prob for all classes and a given testing point\n",
    "\n",
    "    # compute posterior prob for each class\n",
    "    for label in np.unique(ytrain):\n",
    "        # Posterior_c = likelihood * Prior\n",
    "        # Note: it's also divided by marginal prob(holds \"same\" value across all labels) which we can ignore because we need to compute argmax of Posterior_c across all labels)\n",
    "        feature_idx = 0\n",
    "        prior_prob_value =  prior_prob(ytrain, label)\n",
    "        likelihood = 1.0\n",
    "        for feature_value in xtest:\n",
    "            likelihood = likelihood * condition_prob(xtrain, ytrain, feature_idx, feature_value,label)\n",
    "            feature_idx = feature_idx + 1\n",
    "        \n",
    "        post = likelihood * prior_prob_value\n",
    "        posterior_prob_list.append(post)\n",
    "\n",
    "    pred = np.argmax(posterior_prob_list)\n",
    "    return pred\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "output = predict(xtrain, ytrain, xtest[0])\n",
    "print(output)\n",
    "print(ytest[0])\n",
    "output = predict(xtrain, ytrain, xtest[1])\n",
    "print(output)\n",
    "print(ytest[1])\n",
    "output = predict(xtrain, ytrain, xtest[2])\n",
    "print(output)\n",
    "print(ytest[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(xtrain,ytrain, xtest, ytest):\n",
    "    pred = []\n",
    "\n",
    "    for i in range(xtest.shape[0]):\n",
    "        pred_label = predict(xtrain,ytrain,xtest[i])\n",
    "        pred.append(pred_label)\n",
    "    \n",
    "    pred = np.array(pred)\n",
    "    accuracy = np.sum(pred == ytest)/ytest.shape[0]\n",
    "    return accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993846153846154\n"
     ]
    }
   ],
   "source": [
    "print(score(xtrain, ytrain, xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
